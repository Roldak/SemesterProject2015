
\section{Challenging the Assumptions}

In this section, I describe the steps that I followed in order to debug the slowdown observed in the last section, that is, to identify its cause.

\subsection{Interpretation of the Numbers}

First of all, I tried to tweak the parameters of the benchmark to try deducing the cause of the slowdowns. As one could expect, modifying basic items such as the size of the |ArrayBuffer|s did not improve the numbers. Ultimately, I had to dig deeper into what could cause the problem, and to this end rewrote the benchmarking process by hand so that it would be easier to debug and to experiment with the JVM flags. Usually, benchmarking is done through a dedicated framework, such as ScalaMeter, but in this particular case I needed to isolate the benchmark and be able to run it directly. Thinking back about the original problem, one of the cause for the slowdown could have been that hot methods would not get inlined properly. Indeed, the miniboxing transformation generally produces methods that are larger than their generic counterparts, which can prevent inlining. This can be easily detected with a debug build of the HotSpot virtual machine and the |-XX:+PrintCompilation| flag. Unfortunately it did not pay off. Another direction was to obtain a breakdown of the time spent computing and collecting garbage. Indeed, running the benchmark once more with the |-XX:+PrintGC| option yielded a more interesting result: the version using |MbArray|s would spend way more time collecting garbage than the version using |ClassTag|s:

\begin{figure}
\centering
\subfigure[ClassTag version]{
	\lstinputlisting{BenchmarkOutputs/CtVector1.txt}
}
\subfigure[Miniboxed version]{
	\lstinputlisting{BenchmarkOutputs/MbVector1.txt}
}
\caption{Benchmark outputs for ArrayBuffers of 10'000'000 elements}
\label{fig:GcComp}
\end{figure}

In figure \ref{fig:GcComp}, we can see that during one iteration of the benchmark:
\begin{itemize}
  \item The |ClassTag| version spends only |~66ms| collecting garbage.
  \item The |MbArray| version spends up to |~145ms| collecting garbage. 
\end{itemize} 

\vfill

\subsection{Problem with the Current Design}

In order to understand the cause of the slowdown, it is necessary recall how |MbArray|s are currently transformed by the miniboxing plugin. Indeed, the third assumption -- which was presented in section \ref{subsec:assumptions} -- states:
\begin{quote}
\textit{Inside the array, use the miniboxed representation (Long or Double) instead of the unboxed representation, as this side-steps the need for the tag-based dispatch and the primitive conversion.}
\end{quote}
When an |MbArray| is instantiated in a context where its type argument is known to be a primitive type, the miniboxing plugin transforms at compile time the instantiation of the generic |MbArray| into one of its specialized version: |MbArray_J| for an integral type, or |MbArray_D| for a floating point type.
At first, it seemed like a good idea to have only these two specialized versions since intenally, the miniboxing plugin only deals with three representations: |Object|, |long| and |double|. Indeed, storing the values as their miniboxed representation avoids the array type dispatch and coercion costs that would occur in the access procedures if they were stored as their true representation. 

However, the GC printouts from figure \ref{fig:GcComp} show that using the miniboxed representations internally causes significantly more memory to be used when storing integers, up to twice the memory used by raw arrays. Even worse, for booleans, which only need one bit, storing values in the long representation causes the heap fooprint to increase 64 times. In turn, this leads to more GC cycles, which slow down the program execution.

%Now what remains to be done before being able to fix the issue is to explain how the difference in GC time could be so important:
%The first things that stands out is how memory consumption for the |MbArray| version gets up to $800MB$, whereas the |ClassTag| version only reaches $600MB$.

